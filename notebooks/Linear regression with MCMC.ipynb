{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Linear regression with MCMC\n",
    "\n",
    "Author(s): Shajib\n",
    "\n",
    "In this notebook, we will fit a linear model (which simply means a straight\n",
    "line) to some data points. This fitting process has a fancy name:\n",
    "\"Linear regression.\" We will fit the model to daily temperature values\n",
    "for a given city and then **use the best-fit model to predict** future\n",
    "temperatures. The data points have uncertainties that correspond to the 68 percentiles of the range of temperature fluctuations within a day. We want to fit a model\n",
    "\n",
    " $T(d) = m d + b,$\n",
    "\n",
    "where $d$ is the day number (independent variable) and $T$ is the temperature (dependent variable). The model parameters are the slope of\n",
    "the linear relation $m$ and the offset $b$. For a given set of $N$ data points $T_i$, $\\sigma_{T,i}$, $d_i$ with $i=1,\\dots,N$, we want to find the best fit values for $m$ and $b$, and **also their uncertainties**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "8w3tA8-wqsrw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Math"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "Vq0XIMPLqsrz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieving daily temperature data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "uh_RVvjHqsr0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from city_temperatures import CityTemperatures\n",
    "from datetime import datetime\n",
    "\n",
    "# Take a city name that has the first two letters common with your name.\n",
    "# If the plot below comes out empty, then chances are that this city is not\n",
    "# very well-known, in that case try choosing a different city.\n",
    "city_name = \"...\"\n",
    "city_temparatures = CityTemperatures(city_name)\n",
    "\n",
    "start_date = datetime(2022, 11, 1)\n",
    "end_date = datetime(2022, 11, 30)\n",
    "\n",
    "dates, temperature_average, temperature_range = city_temparatures.get_temperatures(\n",
    "    start_date, end_date\n",
    ")\n",
    "\n",
    "\n",
    "day_index = range(len(dates))\n",
    "temperature = temperature_average\n",
    "sigma_temperature = 0.34 * temperature_range\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(\n",
    "    x=day_index, y=temperature, yerr=sigma_temperature, ls=\"none\", marker=\"o\", alpha=0.5\n",
    ")\n",
    "\n",
    "ax.set_xlabel(r\"$d$\")\n",
    "ax.set_ylabel(r\"$T$ (degree Celcius)\")\n",
    "ax.set_title(\n",
    "    f\"Daily temperature values of {city_name} between \"\n",
    "    f'{start_date.strftime(\"%b %d, %y\")} and '\n",
    "    f'{end_date.strftime(\"%b %d, %y\")}'\n",
    ")\n",
    "plt.show()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "esZ6yJmiqsr0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Bayesian way of linear regression\n",
    "\n",
    "We will take the Bayesian approach, which is more common in\n",
    "recent Astronomy. The other way is called the Frequentist approach. You\n",
    "may read [this blog post](https://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/) later on your own time to understand the distinctions.\n",
    "\n",
    "A quick practical distinction to remember is that the Frequentist approach\n",
    "only considers the likelihood function, whereas the Bayesian approach also considers a prior probability function. Both approaches can give you parameter uncertainties.\n",
    "\n",
    "We will first define some functions to compute the likelihood, prior, and \n",
    "posterior probabilities given model parameters. The logarithms of these values are calculated to have better computational accuracies. Otherwise, these values can be very small and vulnerable to floating point error. Then, we will use the MCMC sampling software `emcee` to obtain the posterior probability distribution function (PDF) of the model parameters. Sampling from an unknown distribution makes the distribution known through the distribution of the sampled points, for that reason you would want to sample a large number of points to achieve higher numerical accuracy.\n",
    "\n",
    "\n",
    "Write down the equations for the log likelihood term in your case.\n",
    "\n",
    "...\n",
    "\n",
    "Describe what prior(s) you are choosing on your model parameters.\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "(For reference, here is an example code explained on the `emcee` [website](https://emcee.readthedocs.io/en/stable/tutorials/line/).)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "TKjcsTIeqsr1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_log_likelihood(params):\n",
    "    \"\"\"\n",
    "    Compute the log likelihood value.\n",
    "    :param params: array containing model parameters\n",
    "    :type params: np.array\n",
    "    :return: log likelihood value\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    # write code\n",
    "    ...\n",
    "\n",
    "\n",
    "def get_log_prior(params):\n",
    "    \"\"\"\n",
    "    Get the log prior value.\n",
    "    :param params: array containing model parameters\n",
    "    :type params: np.array\n",
    "    :return: log prior value\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    # write code\n",
    "    ...\n",
    "\n",
    "\n",
    "def get_log_posterior(params):\n",
    "    \"\"\"\n",
    "    Compute the log posterior value.\n",
    "    :param params: array containing model parameters\n",
    "    :type params: np.array\n",
    "    :return: log posterior value\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    log_prior = get_log_prior(params)\n",
    "\n",
    "    if np.isinf(log_prior):\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return get_log_likelihood(params) + log_prior"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "dKCBoFqTqsr1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Now, we will create an instance of the `emcee.EnsembleSampler` class and\n",
    "perform the MCMC sampling.**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "eOUoeFPAqsr2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "...  # import the emcee package\n",
    "\n",
    "init_params = np.array([..., ...])  # insert your initial guess for the model parameters\n",
    "num_step = 1000\n",
    "num_walkers = 40\n",
    "num_params = len(init_params)\n",
    "init_walker_positions = np.random.normal(\n",
    "    loc=init_params, scale=1e-4, size=(num_walkers, num_params)\n",
    ")\n",
    "\n",
    "sampler = emcee.EnsembleSampler(num_walkers, num_params, get_log_posterior)\n",
    "\n",
    "sampler.run_mcmc(init_walker_positions, num_step, progress=True);"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "AxUZksxyqsr2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**`emcee` employs multiple parallel walkers (set by the variable\n",
    "`num_walkers`). Let's plot how these walkers have moved around in the\n",
    "parameter space along the sampling steps.**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "X9TiwjqVqsr2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(num_params, figsize=(10, 7), sharex=True)\n",
    "\n",
    "samples = sampler.get_chain()\n",
    "labels = ...  # make a list of strings for the labels of your model parameters\n",
    "\n",
    "for i in range(num_params):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.2)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "igKUsJaxqsr2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above plot:\n",
    "\n",
    "1. Notice that the chain (which means the walker positions along the steps) has stabilized after a certain step number. This stabilization is called the convergence.\n",
    "2. There is an initial period where the chain has some memory of the\n",
    "initial position. The period until this memory has been lost is called the\n",
    "burnin.\n",
    "3. We want to throw away all the steps until convergence has been reached.\n",
    "Set the value for the `discard` variable to that initial number of steps to be thrown away.\n",
    "4. You would also want to thin the chain because each successive step is\n",
    "correlated with the previous, but you want to have *independent* or *non-correlated* sampled points to provide you the posterior probability\n",
    "distribution. That's done using the `thin` variable below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "N2SFBa3Lqsr3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "discard = 200\n",
    "flat_samples = sampler.get_chain(discard=discard, thin=15, flat=True)\n",
    "\n",
    "for i in range(num_params):\n",
    "    percentile_16, median, percentile_84 = np.percentile(\n",
    "        flat_samples[:, i], [16, 50, 84]\n",
    "    )\n",
    "\n",
    "    text = \"\\mathrm{{{3}}} = {0:.2f}_{{-{1:.2f}}}^{{+{2:.2f}}}\"\n",
    "    text = text.format(\n",
    "        median, median - percentile_16, percentile_84 - median, labels[i]\n",
    "    )\n",
    "    display(Math(text))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "3ocuvoQXqsr3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing the posterior PDF of the model parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "BEFyeavYqsr3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "corner.corner(flat_samples, labels=labels);"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "cvCHoc0uqsr3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above plot is called the corner plot. The 1D histograms along the diagonals are the 1D marginalized PDF for each parameter and give you the best-fit values and uncertainties. The 2D contours show you the joint distribution of a pair of model parameters. What does it mean that this 2D distribution has an elliptical shape oriented diagonally?\n",
    "\n",
    "Answer: ..."
   ],
   "metadata": {
    "id": "YcV4W4pmR8-j"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing our model fit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "DC2KlpFPqsr3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indices = np.random.randint(len(flat_samples), size=500)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "lines = []\n",
    "\n",
    "for n in indices:\n",
    "    sample = flat_samples[n]\n",
    "    param_1 = sample[0]\n",
    "    param_2 = sample[1]\n",
    "\n",
    "    line = ...  # write code to compute the model line for param_1 and param_2\n",
    "    lines.append(line)\n",
    "\n",
    "    ax.plot(day_index, line, \"C1\", alpha=0.03)\n",
    "\n",
    "ax.errorbar(\n",
    "    day_index, temperature, yerr=sigma_temperature, ls=\"none\", marker=\"o\", alpha=0.5\n",
    ")\n",
    "\n",
    "ax.set_xlabel(r\"$d$\")\n",
    "ax.set_ylabel(r\"$T$ (degree Celcius)\")\n",
    "ax.set_title(\n",
    "    f\"Daily temperature values of {city_name} between \"\n",
    "    f'{start_date.strftime(\"%b %d, %y\")} and '\n",
    "    f'{end_date.strftime(\"%b %d, %y\")}'\n",
    ")\n",
    "plt.show()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "6HV1ivQ1qsr4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**In the above figure, how would you interpret the higher-density regions of the orange lines (the region with a deeper shade of orange)?**\n",
    "\n",
    "Answer: ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "ZLvyj_6Eqsr4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Below is an alternative way to visualize the uncertainty of fitted model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "FR50VLOmqsr4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_line = np.mean(lines, axis=0)\n",
    "sigma_line = np.std(lines, axis=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.errorbar(\n",
    "    day_index, temperature, yerr=sigma_temperature, ls=\"none\", marker=\"o\", alpha=0.5\n",
    ")\n",
    "\n",
    "ax.plot(day_index, mean_line, \"k-\")\n",
    "ax.fill_between(\n",
    "    day_index,\n",
    "    y1=mean_line + sigma_line,\n",
    "    y2=mean_line - sigma_line,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(r\"$d$\")\n",
    "ax.set_ylabel(r\"$T$ (degree Celcius)\")\n",
    "ax.set_title(\n",
    "    f\"Daily temperature values of {city_name} between \"\n",
    "    f'{start_date.strftime(\"%b %d, %y\")} and '\n",
    "    f'{end_date.strftime(\"%b %d, %y\")}'\n",
    ")\n",
    "plt.show()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "y1kuyjLoqsr4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Did we choose our priors appropriately?\n",
    "\n",
    "If you are like me when I ran the above procedure for the first time, then you have chosen uniform priors on $m$ and $b$, thinking these priors are uninformative. They are actually not uninformative. Let's see how."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "8DvaXhMkqsr4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create 1000 random samples of m ~ U(-1, 1) and set b = 0\n",
    "m = ...  # m ~ U(-1, 1)\n",
    "b = 0\n",
    "\n",
    "x = np.linspace(-50, 50, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(len(m)):\n",
    "    ax.plot(x, x * m[i] + b, \"k-\", alpha=0.03)\n",
    "\n",
    "ax.set_ylim(-5, 5)\n",
    "ax.set_xlabel(r\"$x$\")\n",
    "ax.set_ylabel(r\"$y$\");"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "3mzoXsnSqsr4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Is there a preferred alignment in the lines? Is this what you intended when\n",
    "you imagined an uninformative prior on the slope of the line?**\n",
    "\n",
    "Answer: ...\n",
    "\n",
    "To have uninformative priors on $m$ and $b$, you would need to put uniform\n",
    "priors on $\\theta = \\tan^{-1} m$ and $b_{\\perp} = b \\cos \\theta$. You can see [here](https://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/) later\n",
    "for an explanation on why these choices make the prior uninformative.\n",
    "\n",
    "Now, let's take $\\theta$ and $b_{\\perp}$ as the parameters that are sampled with uniform prior in the MCMC. However, we are still working with the model:\n",
    "$T(d) = md + b$.\n",
    "\n",
    "Rewrite the likelihood and prior functions in terms of the new\n",
    "model parameter definitions. Then, run the MCMC sampling with `emcee`. Then, convert the $\\theta$ and $b_{\\perp}$ posterior distributions into $m$ and $b$ posterior distributions. Compare the 1D marginalized values of $m$ and $b$ with those you obtained with the previous prior."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "Q-hOrfoLqsr4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# write code. You may use multiple notebook cells as necessary.\n",
    "..."
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "3bh_A086qsr5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction using your model\n",
    "\n",
    "1. Using your best-fit model, predict the temperature in your chosen city on Dec 7, 2022. Your prediction should include uncertainty.\n",
    "2. Similarly, predict the temperatures on Jun 30, 2023\n",
    "and Oct 31, 2023. Are they reasonable predictions? If not, could you think about why?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "WNJeg1M5qsr5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# write code to make your predictions\n",
    "..."
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "PtuhFgilqsr5"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
